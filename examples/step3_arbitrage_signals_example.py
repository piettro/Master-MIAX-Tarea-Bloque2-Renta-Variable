"""
Step 3: Arbitrage Signal Generation - Example Implementation

This example demonstrates the complete Step 3 arbitrage signal generation system,
showing how to detect cross-venue arbitrage opportunities with proper rising edge 
detection and profit calculations.

Key Features Demonstrated:
- Global Max Bid vs Global Min Ask detection
- 1-second persistence rule (1000 snapshots)
- Rising edge detection to prevent double counting
- Comprehensive profit calculations
- Integration with existing consolidated tape

Author: GitHub Copilot
Date: December 2025
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import matplotlib.pyplot as plt

# Add src to path for imports
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from src.models.arbitrage_signals import (
    ArbitrageSignalGenerator, 
    ArbitrageSignalManager, 
    ArbitrageSignalFactory,
    OpportunityStatus
)
from src.models.consolidated_tape import ConsolidatedTape, VenueData


def create_sample_market_data():
    """
    Create sample consolidated tape data with embedded arbitrage opportunities
    
    Returns:
        DataFrame with realistic market data containing arbitrage opportunities
    """
    print("ğŸ“Š Creating sample market data with arbitrage opportunities...")
    
    # Create 10 seconds of market data (10,000 snapshots at 1ms intervals)
    n_snapshots = 10000
    timestamps = [datetime.now() + timedelta(milliseconds=i) for i in range(n_snapshots)]
    
    # Set random seed for reproducible results
    np.random.seed(42)
    
    # Base parameters
    base_price = 100.0
    bid_ask_spread = 0.02
    
    # Generate realistic price walks for each venue
    aquis_mid = base_price + np.cumsum(np.random.normal(0, 0.0005, n_snapshots))
    bme_mid = base_price + np.cumsum(np.random.normal(0, 0.0005, n_snapshots))
    cboe_mid = base_price + np.cumsum(np.random.normal(0, 0.0005, n_snapshots))
    turquoise_mid = base_price + np.cumsum(np.random.normal(0, 0.0005, n_snapshots))
    
    # Calculate bid/ask prices with typical spreads
    data = pd.DataFrame({
        'timestamp': timestamps,
        'AQUIS_bid': aquis_mid - bid_ask_spread/2,
        'AQUIS_ask': aquis_mid + bid_ask_spread/2,
        'AQUIS_bid_qty': np.random.randint(100, 2000, n_snapshots),
        'AQUIS_ask_qty': np.random.randint(100, 2000, n_snapshots),
        
        'BME_bid': bme_mid - bid_ask_spread/2,
        'BME_ask': bme_mid + bid_ask_spread/2,
        'BME_bid_qty': np.random.randint(100, 2000, n_snapshots),
        'BME_ask_qty': np.random.randint(100, 2000, n_snapshots),
        
        'CBOE_bid': cboe_mid - bid_ask_spread/2,
        'CBOE_ask': cboe_mid + bid_ask_spread/2,
        'CBOE_bid_qty': np.random.randint(100, 2000, n_snapshots),
        'CBOE_ask_qty': np.random.randint(100, 2000, n_snapshots),
        
        'TURQUOISE_bid': turquoise_mid - bid_ask_spread/2,
        'TURQUOISE_ask': turquoise_mid + bid_ask_spread/2,
        'TURQUOISE_bid_qty': np.random.randint(100, 2000, n_snapshots),
        'TURQUOISE_ask_qty': np.random.randint(100, 2000, n_snapshots)
    }, index=timestamps)
    
    # Inject arbitrage opportunities at specific intervals
    print("ğŸ¯ Injecting arbitrage opportunities...")
    
    arbitrage_intervals = [1000, 2500, 4000, 6500, 8000]  # Snapshot indices for opportunities
    
    for start_idx in arbitrage_intervals:
        end_idx = min(start_idx + 1200, len(data))  # 1.2 seconds duration (> 1 second persistence rule)
        
        # Create arbitrage: AQUIS has highest bid, BME has lowest ask
        data.iloc[start_idx:end_idx, data.columns.get_loc('AQUIS_bid')] += 0.05
        data.iloc[start_idx:end_idx, data.columns.get_loc('BME_ask')] -= 0.03
        
        print(f"   - Arbitrage opportunity: snapshots {start_idx}-{end_idx}")
        print(f"     AQUIS bid elevated, BME ask lowered")
    
    print(f"âœ“ Generated {len(data)} snapshots with {len(arbitrage_intervals)} arbitrage opportunities")
    return data


def demonstrate_signal_generation():
    """
    Demonstrate Step 3 arbitrage signal generation with realistic scenarios
    """
    print("\\n" + "="*80)
    print("STEP 3: ARBITRAGE SIGNAL GENERATION DEMONSTRATION")
    print("="*80)
    
    # Create sample data
    market_data = create_sample_market_data()
    
    # Initialize signal generation system
    print("\\nğŸ”§ Initializing arbitrage signal generation system...")
    
    # Create different types of generators for comparison
    generators = {
        'Standard (1000 snapshots)': ArbitrageSignalFactory.create_standard_generator(),
        'High Frequency (100 snapshots)': ArbitrageSignalFactory.create_high_frequency_generator(),
        'Conservative (2000 snapshots)': ArbitrageSignalFactory.create_conservative_generator()
    }
    
    # Test each generator
    results = {}
    
    for name, generator in generators.items():
        print(f"\\nğŸ“ˆ Testing {name} generator...")
        
        manager = ArbitrageSignalManager(generator)
        opportunities_detected = []
        
        # Process data in chunks to simulate real-time processing
        chunk_size = 100
        for i in range(0, len(market_data), chunk_size):
            end_idx = min(i + chunk_size, len(market_data))
            current_data = market_data.iloc[:end_idx]
            
            result = manager.process_market_data(current_data)
            opportunities_detected.extend(result['new_opportunities'])
        
        # Collect results
        stats = generator.get_statistics()
        summary = manager.get_opportunity_summary()
        venue_analysis = manager.analyze_venue_performance()
        
        results[name] = {
            'generator': generator,
            'manager': manager,
            'opportunities': opportunities_detected,
            'statistics': stats,
            'summary': summary,
            'venue_analysis': venue_analysis
        }
        
        # Print summary for this generator
        print(f"   ğŸ“Š Results Summary:")
        print(f"      - Opportunities detected: {stats['total_opportunities_detected']}")
        print(f"      - Total profit potential: ${stats['total_profit_potential']:.2f}")
        print(f"      - Snapshots processed: {stats['total_snapshots_processed']}")
        if venue_analysis.get('most_profitable_pair'):
            pair, profit = venue_analysis['most_profitable_pair']
            print(f"      - Most profitable pair: {pair[0]} -> {pair[1]} (${profit:.2f})")
    
    return results, market_data


def analyze_opportunity_timing(results, market_data):
    """
    Analyze the timing and characteristics of detected opportunities
    """
    print("\\n" + "="*60)
    print("OPPORTUNITY TIMING ANALYSIS")
    print("="*60)
    
    for generator_name, result in results.items():
        print(f"\\nğŸ“Š {generator_name}:")
        
        opportunities = result['opportunities']
        if not opportunities:
            print("   No opportunities detected")
            continue
        
        # Analyze timing patterns
        detection_times = [opp.detection_time for opp in opportunities]
        profits = [opp.total_profit for opp in opportunities]
        durations = [(opp.expiry_time - opp.detection_time).total_seconds() for opp in opportunities]
        
        print(f"   ğŸ¯ Opportunity Characteristics:")
        print(f"      - Count: {len(opportunities)}")
        print(f"      - Avg profit: ${np.mean(profits):.4f}")
        print(f"      - Max profit: ${np.max(profits):.4f}")
        print(f"      - Min profit: ${np.min(profits):.4f}")
        print(f"      - Avg duration: {np.mean(durations):.1f} seconds")
        
        # Check for rising edge effectiveness
        unique_opportunity_ids = set(opp.opportunity_id for opp in opportunities)
        print(f"      - Unique opportunities: {len(unique_opportunity_ids)}")
        print(f"      - Avg detections per unique: {len(opportunities) / len(unique_opportunity_ids):.1f}")


def demonstrate_rising_edge_detection():
    """
    Demonstrate rising edge detection to prevent double counting
    """
    print("\\n" + "="*60)
    print("RISING EDGE DETECTION DEMONSTRATION")
    print("="*60)
    
    # Create simple test case with persistent arbitrage
    timestamps = [datetime.now() + timedelta(milliseconds=i*10) for i in range(200)]  # 2 seconds of data
    
    # Persistent arbitrage for first 150 snapshots, then gap, then reappearance
    persistent_data = pd.DataFrame({
        'AQUIS_bid': [100.05] * 150 + [100.02] * 25 + [100.05] * 25,  # Arbitrage, gap, arbitrage
        'AQUIS_ask': [100.07] * 200,
        'BME_bid': [100.03] * 200,
        'BME_ask': [100.02] * 150 + [100.04] * 25 + [100.02] * 25,   # Arbitrage, gap, arbitrage
        'AQUIS_bid_qty': [1000] * 200,
        'AQUIS_ask_qty': [1000] * 200,
        'BME_bid_qty': [1000] * 200,
        'BME_ask_qty': [1000] * 200
    }, index=timestamps)
    
    # Test rising edge detection
    generator = ArbitrageSignalFactory.create_standard_generator()
    manager = ArbitrageSignalManager(generator)
    
    all_opportunities = []
    
    print("\\nğŸ” Processing persistent arbitrage scenario...")
    
    for i in range(len(persistent_data)):
        current_data = persistent_data.iloc[:i+1]
        result = manager.process_market_data(current_data)
        
        if result['new_opportunities']:
            for opp in result['new_opportunities']:
                print(f"   Snapshot {i}: NEW opportunity {opp.opportunity_id}")
                all_opportunities.append((i, opp))
    
    print(f"\\nâœ“ Rising edge detection summary:")
    print(f"   - Total snapshots with arbitrage condition: 175")
    print(f"   - Opportunities detected (rising edge): {len(all_opportunities)}")
    print(f"   - Expected detections: 2 (initial + reappearance)")
    
    # Verify we only got rising edges
    if len(all_opportunities) == 2:
        print("   âœ… Rising edge detection working correctly!")
    else:
        print("   âš ï¸  Unexpected number of detections - check logic")


def create_performance_visualization(results, market_data):
    """
    Create visualizations of arbitrage opportunities and performance
    """
    print("\\nğŸ“ˆ Creating performance visualizations...")
    
    fig, axes = plt.subplots(2, 2, figsize=(15, 10))
    fig.suptitle('Step 3: Arbitrage Signal Generation Analysis', fontsize=16)
    
    # Plot 1: Market data with arbitrage opportunities
    ax1 = axes[0, 0]
    sample_data = market_data.iloc[::100]  # Sample every 100th point for visibility
    
    ax1.plot(sample_data.index, sample_data['AQUIS_bid'], label='AQUIS Bid', alpha=0.7)
    ax1.plot(sample_data.index, sample_data['BME_ask'], label='BME Ask', alpha=0.7)
    ax1.plot(sample_data.index, sample_data['CBOE_bid'], label='CBOE Bid', alpha=0.5)
    ax1.plot(sample_data.index, sample_data['TURQUOISE_ask'], label='TURQUOISE Ask', alpha=0.5)
    
    # Mark arbitrage opportunities
    standard_opps = results['Standard (1000 snapshots)']['opportunities']
    for opp in standard_opps[:5]:  # Show first 5 opportunities
        ax1.axvline(opp.detection_time, color='red', linestyle='--', alpha=0.8)
    
    ax1.set_title('Market Data with Arbitrage Opportunities')
    ax1.set_ylabel('Price')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Plot 2: Opportunities by generator type
    ax2 = axes[0, 1]
    generator_names = list(results.keys())
    opportunity_counts = [results[name]['statistics']['total_opportunities_detected'] for name in generator_names]
    
    bars = ax2.bar(range(len(generator_names)), opportunity_counts, 
                   color=['blue', 'orange', 'green'])
    ax2.set_title('Opportunities Detected by Generator Type')
    ax2.set_ylabel('Number of Opportunities')
    ax2.set_xticks(range(len(generator_names)))
    ax2.set_xticklabels([name.split()[0] for name in generator_names], rotation=45)
    
    # Add value labels on bars
    for bar, count in zip(bars, opportunity_counts):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, 
                str(count), ha='center', va='bottom')
    
    # Plot 3: Profit potential by generator
    ax3 = axes[1, 0]
    profit_potentials = [results[name]['statistics']['total_profit_potential'] for name in generator_names]
    
    bars = ax3.bar(range(len(generator_names)), profit_potentials, 
                   color=['blue', 'orange', 'green'])
    ax3.set_title('Total Profit Potential by Generator Type')
    ax3.set_ylabel('Total Profit ($)')
    ax3.set_xticks(range(len(generator_names)))
    ax3.set_xticklabels([name.split()[0] for name in generator_names], rotation=45)
    
    # Add value labels on bars
    for bar, profit in zip(bars, profit_potentials):
        ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, 
                f'${profit:.2f}', ha='center', va='bottom')
    
    # Plot 4: Venue pair performance
    ax4 = axes[1, 1]
    standard_analysis = results['Standard (1000 snapshots)']['venue_analysis']
    
    if standard_analysis.get('opportunity_counts_by_venue_pair'):
        pairs = list(standard_analysis['opportunity_counts_by_venue_pair'].keys())
        counts = list(standard_analysis['opportunity_counts_by_venue_pair'].values())
        
        pair_labels = [f"{pair[0]}â†’{pair[1]}" for pair in pairs]
        
        bars = ax4.bar(range(len(pairs)), counts, color='purple', alpha=0.7)
        ax4.set_title('Opportunities by Venue Pair')
        ax4.set_ylabel('Number of Opportunities')
        ax4.set_xticks(range(len(pairs)))
        ax4.set_xticklabels(pair_labels, rotation=45)
        
        # Add value labels on bars
        for bar, count in zip(bars, counts):
            ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, 
                    str(count), ha='center', va='bottom')
    else:
        ax4.text(0.5, 0.5, 'No venue pair data available', ha='center', va='center', 
                transform=ax4.transAxes)
        ax4.set_title('Opportunities by Venue Pair')
    
    plt.tight_layout()
    
    # Save the plot
    plot_filename = "step3_arbitrage_signals_analysis.png"
    plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
    print(f"   âœ“ Visualization saved as {plot_filename}")
    
    plt.show()


def main():
    """
    Main demonstration of Step 3: Arbitrage Signal Generation
    """
    print("ğŸš€ Starting Step 3: Arbitrage Signal Generation Demonstration")
    
    try:
        # Demonstrate signal generation
        results, market_data = demonstrate_signal_generation()
        
        # Analyze opportunity timing
        analyze_opportunity_timing(results, market_data)
        
        # Demonstrate rising edge detection
        demonstrate_rising_edge_detection()
        
        # Create visualizations
        create_performance_visualization(results, market_data)
        
        # Final summary
        print("\\n" + "="*80)
        print("STEP 3 DEMONSTRATION COMPLETE")
        print("="*80)
        
        print("\\nğŸ¯ Key Features Demonstrated:")
        print("   âœ… Global Max Bid vs Global Min Ask detection")
        print("   âœ… Arbitrage condition: Max Bid > Min Ask")
        print("   âœ… Profit calculation: (Max Bid - Min Ask) * Min(BidQty, AskQty)")
        print("   âœ… Rising edge detection (1-second persistence rule)")
        print("   âœ… Duplicate opportunity prevention")
        print("   âœ… Cross-venue signal generation")
        
        print("\\nğŸ“Š Performance Summary:")
        standard_stats = results['Standard (1000 snapshots)']['statistics']
        print(f"   - Snapshots processed: {standard_stats['total_snapshots_processed']:,}")
        print(f"   - Opportunities detected: {standard_stats['total_opportunities_detected']}")
        print(f"   - Total profit potential: ${standard_stats['total_profit_potential']:.2f}")
        print(f"   - Processing rate: {standard_stats['total_snapshots_processed']/10:.0f} snapshots/second")
        
        print("\\nğŸ”„ Integration Ready:")
        print("   - Seamlessly integrates with existing consolidated tape")
        print("   - Compatible with all venue extractors")
        print("   - Ready for Step 4: Execution Strategy")
        
        return True
        
    except Exception as e:
        print(f"\\nâŒ Error in demonstration: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = main()
    if not success:
        sys.exit(1)
    
    print("\\nâœ¨ Step 3 implementation complete and ready for production use!")